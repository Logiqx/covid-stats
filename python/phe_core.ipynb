{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHE Core\n",
    "\n",
    "Created by Michael George (AKA Logiqx)\n",
    "\n",
    "Website: https://logiqx.github.io/covid-stats/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Standard python libraries plus determination of projdir, basic printable class, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "import csv\n",
    "\n",
    "import common_core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Data to download via the API - cases, patients, deaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT = \"https://api.coronavirus.data.gov.uk/v1/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only using England for now due to the availability of age demographics, etc\n",
    "nationNames = [\"England\"]\n",
    "\n",
    "# All 9 regions in England\n",
    "regionNames = [\"North West\", \"North East\", \"Yorkshire and The Humber\", \"West Midlands\", \"East Midlands\",\n",
    "             \"East of England\", \"London\", \"South East\", \"South West\"]\n",
    "\n",
    "# All 7 NHS regions in England\n",
    "nhsRegionNames = [\"North West\", \"North East and Yorkshire\", \"Midlands\",\n",
    "                  \"East of England\", \"London\", \"South East\", \"South West\"]\n",
    "\n",
    "# A selection of lower tier local authorities in Dorset, Hertfordshire, Birmingham, Derbyshire and London (LTLA)\n",
    "ltlaNames = [\"Dorset\", \"Bournemouth, Christchurch and Poole\",\n",
    "             \"Stevenage\", \"Welwyn Hatfield\", \"North Hertfordshire\", \"East Hertfordshire\",\n",
    "             \"Sandwell\", \"Dudley\", \"Birmingham\",\n",
    "             \"Derbyshire Dales\", \"North East Derbyshire\", \"High Peak\", \"Sheffield\",\n",
    "             \"Croydon\"]\n",
    "\n",
    "# Combine all of these area types into a single list\n",
    "areas = [(\"nation\", [\"England\"]), (\"region\", regionNames), (\"nhsregion\", nhsRegionNames), (\"ltla\", ltlaNames)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "casesStructure = {\n",
    "    \"cases\": \"newCasesBySpecimenDate\", # Cases by specimen date\n",
    "    \"casesRollingSum\": \"newCasesBySpecimenDateRollingSum\", # Total cases (7-day average)\n",
    "    \"casesRollingRate\": \"newCasesBySpecimenDateRollingRate\", # Rate of cases per 100K over 7 days\n",
    "    \"casesAgeDemographics\": \"newCasesBySpecimenDateAgeDemographics\", # Demographics\n",
    "    \"casesReported\": \"newCasesByPublishDate\" # Cases by date reported\n",
    "}\n",
    "\n",
    "patientsStructure = {\n",
    "    \"hospitalAdmissions\": \"newAdmissions\", # Patients admitted to hospital\n",
    "    \"hospitalPatients\": \"hospitalCases\", # Patients in hospital\n",
    "    \"hospitalPatientsMv\": \"covidOccupiedMVBeds\" # Patients in mechanical ventilation beds\n",
    "}\n",
    "\n",
    "deathsStructure = {\n",
    "    \"deaths\": \"newDeaths28DaysByDeathDate\", # Deaths within 28d of +ve test by date of death\n",
    "    \"deathsRollingSum\": \"newDeaths28DaysByDeathDateRollingSum\", # Total deaths by date of death (7-day average)\n",
    "    \"deathsRollingRate\": \"newDeaths28DaysByDeathDateRollingRate\", # Rate of deaths per 100K over 7 days\n",
    "    \"deathsAgeDemographics\": \"newDeaths28DaysByDeathDateAgeDemographics\", # Demographics\n",
    "    \"deathsReported\": \"newDeaths28DaysByPublishDate\" # Deaths within 28d of +ve test by date reported\n",
    "}\n",
    "\n",
    "onsStructure = {\n",
    "    \"deathsRegistered\": \"newOnsDeathsByRegistrationDate\" # COVID-19 on the death certificate\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ageDemographics = [\n",
    "    '00_04', '05_09', '10_14', '15_19', '20_24', '25_29',\n",
    "    '30_34', '35_39', '40_44', '45_49', '50_54', '55_59',\n",
    "    '60_64', '65_69', '70_74', '75_79', '80_84', '85_89', '90+'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area Class\n",
    "\n",
    "Download data via the API and prepare it for analysis.\n",
    "\n",
    "Supports nations, regions and LTLAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Area(common_core.Printable):\n",
    "    def __init__(self, areaType, areaName):\n",
    "        \"\"\"Initialisise the area object\"\"\"\n",
    "\n",
    "        self.areaType = areaType\n",
    "        self.areaName = areaName\n",
    "\n",
    "        self.safeName = areaName.lower().replace(' ', '_').replace(',', '')\n",
    "        for word in 'of', 'and', 'the':\n",
    "            self.safeName = self.safeName.replace(word + '_', '')\n",
    "\n",
    "        self.csvName = self.safeName + '.csv'\n",
    "        \n",
    "\n",
    "    def getRawPath(self, period):\n",
    "        \"\"\"Get path for raw data\"\"\"\n",
    "        rawPath = os.path.join(common_core.projdir, \"data\", \"phe-dashboard\", \"raw\", period, self.areaType)\n",
    "\n",
    "        return rawPath\n",
    "\n",
    "        \n",
    "    def getCsvPath(self, period, category):\n",
    "        \"\"\"Get path for csv data\"\"\"\n",
    "        csvPath = os.path.join(common_core.projdir, \"data\", \"phe-dashboard\", \"csv\", period, category, self.areaType)\n",
    "\n",
    "        return csvPath\n",
    "\n",
    "        \n",
    "    def download(self, period = \"daily\"):\n",
    "        \"\"\"Download data from PHE dashboard\"\"\"\n",
    "\n",
    "        # Catch all exceptions\n",
    "        try:\n",
    "            filters = [\n",
    "                f\"areaType={self.areaType}\",\n",
    "                f\"areaName={self.areaName}\"\n",
    "            ]\n",
    "\n",
    "            structure = {\n",
    "                \"date\": \"date\",\n",
    "                \"areaName\": \"areaName\"\n",
    "            }\n",
    "\n",
    "            if period == \"weekly\":\n",
    "                if self.areaType in ['nation', 'region', 'ltla']:\n",
    "                    structure.update(onsStructure)\n",
    "            else:\n",
    "                if self.areaType in ['nation', 'region', 'ltla']:\n",
    "                    structure.update(casesStructure)\n",
    "                    structure.update(deathsStructure)\n",
    "                if self.areaType in ['nation', 'nhsregion']:\n",
    "                    structure.update(patientsStructure)\n",
    "\n",
    "            api_params = {\n",
    "                \"filters\": str.join(\";\", filters),\n",
    "                \"structure\": json.dumps(structure, separators=(\",\", \":\")),\n",
    "                \"format\": \"csv\"\n",
    "            }\n",
    "\n",
    "            # Download raw data - hybrid of CSV and Python dictionaries\n",
    "            response = requests.get(ENDPOINT, params=api_params, timeout=10)\n",
    "            assert response.status_code == 200, f\"Failed request for {self.areaName}: {response.status_code} {response.text}\"\n",
    "\n",
    "            # Ensure raw path exists\n",
    "            rawPath = self.getRawPath(period)\n",
    "            if not os.path.exists(rawPath):\n",
    "                os.makedirs(rawPath)\n",
    "\n",
    "            # Save raw data\n",
    "            rawFn = os.path.join(rawPath, self.csvName)\n",
    "            with open(rawFn, 'w') as f:\n",
    "                f.write(response.content.decode())\n",
    "\n",
    "        # General catch all to report exceptions then abort\n",
    "        except:\n",
    "            print(f\"Failed to download {period} data for {self.areaName}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    def downloadDaily(self):\n",
    "        \"\"\"Download daily data for analysis\"\"\"\n",
    "\n",
    "        # Daily data is available for all area types\n",
    "        print(f\"Downloading {self.areaName}...\")\n",
    "        self.download()\n",
    "\n",
    "\n",
    "    def downloadWeekly(self):\n",
    "        \"\"\"Download weekly data for analysis\"\"\"\n",
    "\n",
    "        # ONS data is not available for 'nhsregion'\n",
    "        if self.areaType in ['nation', 'region', 'ltla']:\n",
    "            print(f\"Downloading {self.areaName}...\")\n",
    "            self.download(\"weekly\")\n",
    "\n",
    "\n",
    "    def prepare(self, category, period = \"daily\"):\n",
    "        \"\"\"Prepare data for analysis\"\"\"\n",
    "\n",
    "        def getColNos(row, category):\n",
    "            \"\"\"Get column numbers relevant to the category\"\"\"\n",
    "\n",
    "            if category == \"cases\":\n",
    "                structure = casesStructure\n",
    "            elif category == \"patients\":\n",
    "                structure = patientsStructure\n",
    "            elif category == \"deaths\":\n",
    "                structure = deathsStructure\n",
    "            elif category == \"ons\":\n",
    "                structure = onsStructure\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported category - {category}\") \n",
    "\n",
    "            # Always include date and areaName - see default \"structure\" above\n",
    "            colNos = [0, 1]\n",
    "\n",
    "            # Other columns are dependent on the category and the fields defined in its \"structure\"\n",
    "            for colNo in range(len(row)):\n",
    "                if row[colNo] in structure:\n",
    "                    # Age demographics are not available for deaths within \"ltla\"\n",
    "                    if category == \"deaths\" and self.areaType == \"ltla\":\n",
    "                        if not row[colNo].endswith(\"Demographics\"):\n",
    "                            colNos.append(colNo)\n",
    "                    else:\n",
    "                        colNos.append(colNo)\n",
    "\n",
    "            return colNos\n",
    "\n",
    "\n",
    "        def getColNames(row, colNos):\n",
    "            \"\"\"Get column names relevant to the category\"\"\"\n",
    "\n",
    "            # Always include date and areaName\n",
    "            colNames = []\n",
    "\n",
    "            # Other columns are dependent on the category and its structure\n",
    "            for colNo in colNos:\n",
    "                # Demographics are provided as a Python structure\n",
    "                if row[colNo].endswith(\"Demographics\"):\n",
    "                    # Only use the demographic fields that are actually required\n",
    "                    for ageDemographic in ageDemographics:\n",
    "                        colNames.append(f\"{category}{ageDemographic}\")\n",
    "                        colNames.append(f\"{category}RollingSum{ageDemographic}\")\n",
    "                        colNames.append(f\"{category}RollingRate{ageDemographic}\")\n",
    "                else:\n",
    "                    colNames.append(row[colNo])\n",
    "                \n",
    "            return colNames\n",
    "\n",
    "\n",
    "        def getRowValues(row, colNos):\n",
    "            \"\"\"Get row values for specific field numbers\"\"\"\n",
    "\n",
    "            tidyRow = []\n",
    "            for colNo in colNos:\n",
    "                # Checking for \"[\" is a hack but it detects Python structures\n",
    "                if row[colNo].startswith('['):\n",
    "                    items = eval(row[colNo])\n",
    "                    # Pick out the age demographics that are required\n",
    "                    for ageDemographic in ageDemographics:\n",
    "                        found = False\n",
    "                        for item in items:\n",
    "                            if item[\"age\"] == ageDemographic:\n",
    "                                tidyRow.append(item[category])\n",
    "                                tidyRow.append(item[\"rollingSum\"])\n",
    "                                tidyRow.append(item[\"rollingRate\"])\n",
    "                                found = True\n",
    "                                break\n",
    "\n",
    "                        # Some records do not include the age demographics, just an empty list\n",
    "                        if found == False:\n",
    "                            tidyRow.append(\"\")\n",
    "                            tidyRow.append(\"\")\n",
    "                            tidyRow.append(\"\")\n",
    "                else:\n",
    "                    # Copy value of regular column\n",
    "                    tidyRow.append(row[colNo])\n",
    "\n",
    "            return tidyRow\n",
    "\n",
    "\n",
    "        # Catch all exceptions\n",
    "        try:\n",
    "            # Determine raw filename\n",
    "            rawPath = self.getRawPath(period)\n",
    "            rawFn = os.path.join(rawPath, self.csvName)\n",
    "\n",
    "            # Ensure the CSV path exists\n",
    "            csvPath = self.getCsvPath(period, category)\n",
    "            if not os.path.exists(csvPath):\n",
    "                os.makedirs(csvPath)\n",
    "\n",
    "            # Generate the CSV from raw data\n",
    "            csvFn = os.path.join(csvPath, self.csvName)\n",
    "            with open(csvFn, 'w') as csvFile:\n",
    "                writer = csv.writer(csvFile)\n",
    "\n",
    "                with open(rawFn, 'r') as f:\n",
    "                    reader = csv.reader(f, delimiter = ',')\n",
    "                    rows = []\n",
    "                    rowNo = 0\n",
    "\n",
    "                    for row in reader:\n",
    "                        if rowNo == 0:\n",
    "                            # First row is column names\n",
    "                            colNos = getColNos(row, category)\n",
    "                            colNames = getColNames(row, colNos)\n",
    "                        else:\n",
    "                            # Subsequent rows are actual data\n",
    "                            row = getRowValues(row, colNos)\n",
    "                            rows.append(row)\n",
    "\n",
    "                        rowNo += 1\n",
    "\n",
    "                    # PHE publish data in reverse chronological order, hence the use of \"reverse\"\n",
    "                    rows.reverse()\n",
    "\n",
    "                    writer.writerow(colNames)\n",
    "                    writer.writerows(rows)\n",
    "\n",
    "        # General catch all to report exceptions then abort\n",
    "        except:\n",
    "            print(f\"Failed to convert {period} {category} for {self.areaName}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    def prepareDaily(self):\n",
    "        \"\"\"Prepare daily data for analysis\"\"\"\n",
    "\n",
    "        print(f\"Preparing {self.areaName}...\")\n",
    "\n",
    "        # There is no daily case / death data for the \"nhsregion\" area type\n",
    "        if self.areaType in [\"nation\", \"region\", \"ltla\"]:\n",
    "            self.prepare(\"cases\")\n",
    "            self.prepare(\"deaths\")\n",
    "\n",
    "        # Patient data is only available for \"nation\" and \"nhsregion\", not \"ltla\"\n",
    "        if self.areaType in [\"nation\", \"nhsregion\"]:\n",
    "            self.prepare(\"patients\")\n",
    "\n",
    "\n",
    "    def prepareWeekly(self):\n",
    "        \"\"\"Prepare weekly data for analysis\"\"\"\n",
    "\n",
    "        if self.areaType in [\"nation\", \"region\", \"ltla\"]:\n",
    "            print(f\"Preparing {self.areaName}...\")\n",
    "            self.prepare(\"ons\", \"weekly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
