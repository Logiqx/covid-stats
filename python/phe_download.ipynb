{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHE Download\n",
    "\n",
    "Created by Michael George (AKA Logiqx)\n",
    "\n",
    "Website: https://logiqx.github.io/covid-stats/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PHE Core\n",
    "\n",
    "Import library for working with PHE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "import common_core\n",
    "import phe_core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENDPOINT = \"https://api.coronavirus.data.gov.uk/v1/data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PHE_SURVEILLANCE = \"phe-surveillance\"\n",
    "surveillancePath = os.path.join(common_core.dataDir, PHE_SURVEILLANCE, \"raw\")\n",
    "\n",
    "surveillanceUrl = \"https://www.gov.uk/government/statistics/national-flu-and-covid-19-surveillance-reports\"\n",
    "surveillanceFiles = [\n",
    "    (\"weekly\", \"Weekly_Influenza_and_COVID19_report_data_.*\\.xlsx$\")\n",
    "]\n",
    "\n",
    "legacySurveillanceUrl = \"https://www.gov.uk/government/publications/national-covid-19-surveillance-reports\"\n",
    "legacySurveillanceFiles = [\n",
    "    (\"weekly\", \"Weekly_COVID19_report_data_.*\\.xlsx$\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Area Download\n",
    "\n",
    "Class to download data via the API.\n",
    "\n",
    "Supports nations, regions and LTLAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AreaDownload(common_core.Printable):\n",
    "    def __init__(self, areaType, areaName):\n",
    "        \"\"\"Initialisise the area object\"\"\"\n",
    "\n",
    "        self.areaType = areaType\n",
    "        self.areaName = areaName\n",
    "\n",
    "        self.safeName = common_core.getSafeName(areaName)\n",
    "        self.csvName = self.safeName + '.csv'\n",
    "        \n",
    "\n",
    "    def download(self, period = \"daily\"):\n",
    "        \"\"\"Download data from PHE dashboard\"\"\"\n",
    "\n",
    "        # Catch all exceptions\n",
    "        try:\n",
    "            filters = [\n",
    "                f\"areaType={self.areaType}\",\n",
    "                f\"areaName={self.areaName}\"\n",
    "            ]\n",
    "\n",
    "            structure = {\n",
    "                \"date\": \"date\",\n",
    "                \"areaName\": \"areaName\"\n",
    "            }\n",
    "\n",
    "            if period == \"weekly\":\n",
    "                if self.areaType in ['overview', 'nation', 'region', 'ltla']:\n",
    "                    structure.update(phe_core.onsStructure)\n",
    "            else:\n",
    "                if self.areaType in ['overview', 'nation', 'region', 'ltla']:\n",
    "                    structure.update(phe_core.casesStructure)\n",
    "                    structure.update(phe_core.deathsStructure)\n",
    "                if self.areaType in ['overview', 'nation', 'nhsregion']:\n",
    "                    structure.update(phe_core.patientsStructure)\n",
    "\n",
    "            api_params = {\n",
    "                \"filters\": str.join(\";\", filters),\n",
    "                \"structure\": json.dumps(structure, separators=(\",\", \":\")),\n",
    "                \"format\": \"csv\"\n",
    "            }\n",
    "\n",
    "            dirName = rawPath = os.path.join(common_core.dataDir, phe_core.PHE_DASHBOARD, \"raw\", period, self.areaType)\n",
    "            fileName = os.path.join(dirName, self.csvName)\n",
    "            partName = fileName.replace(common_core.dataDir, \"\")[1:]\n",
    "\n",
    "            print(f\"Downloading {partName}...\")\n",
    "\n",
    "            # Allow up to 3 attempts\n",
    "            for attempt in range(3):\n",
    "                try:\n",
    "                    response = requests.get(ENDPOINT, params=api_params, timeout=10)\n",
    "                    break\n",
    "                except:\n",
    "                    time.sleep(1)\n",
    "\n",
    "            assert response.status_code == 200, f\"Failed request for {self.areaName}: {response.status_code} {response.text}\"\n",
    "\n",
    "            if not os.path.exists(dirName):\n",
    "                os.makedirs(dirName)\n",
    "\n",
    "            with open(fileName, 'w') as f:\n",
    "                f.write(response.content.decode())\n",
    "\n",
    "        # General catch all to report exceptions then abort\n",
    "        except:\n",
    "            print(f\"Failed to download {period} data for {self.areaName}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "    def downloadDaily(self):\n",
    "        \"\"\"Download daily data for analysis\"\"\"\n",
    "\n",
    "        # Daily data is available for all area types\n",
    "        self.download()\n",
    "\n",
    "\n",
    "    def downloadWeekly(self):\n",
    "        \"\"\"Download weekly data for analysis\"\"\"\n",
    "\n",
    "        # ONS data is not available for 'nhsregion'\n",
    "        if self.areaType in ['overview', 'nation', 'region', 'ltla']:\n",
    "            self.download(\"weekly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Surveillance Data\n",
    "\n",
    "Simple function to download COVID-19 and Flu surveillance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadSurveillance(skipExisting=common_core.skipExisting, verbose=common_core.verbose):\n",
    "    webDownload = common_core.WebDownload(skipExisting=skipExisting, verbose=verbose)\n",
    "    files = webDownload.downloadFiles(surveillancePath, surveillanceUrl, surveillanceFiles)\n",
    "    files += webDownload.downloadFiles(surveillancePath, legacySurveillanceUrl, legacySurveillanceFiles)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Downloading daily dashboard data ---\n",
      "Downloading phe-dashboard/raw/daily/overview/united_kingdom.csv...\n",
      "Downloading phe-dashboard/raw/daily/nation/england.csv...\n",
      "Downloading phe-dashboard/raw/daily/nation/scotland.csv...\n",
      "Downloading phe-dashboard/raw/daily/nation/wales.csv...\n",
      "Downloading phe-dashboard/raw/daily/nation/northern_ireland.csv...\n",
      "Downloading phe-dashboard/raw/daily/region/north_east.csv...\n",
      "Downloading phe-dashboard/raw/daily/region/north_west.csv...\n",
      "Downloading phe-dashboard/raw/daily/region/yorkshire_humber.csv...\n",
      "Downloading phe-dashboard/raw/daily/region/east_midlands.csv...\n",
      "Downloading phe-dashboard/raw/daily/region/west_midlands.csv...\n",
      "Downloading phe-dashboard/raw/daily/region/east_england.csv...\n",
      "Downloading phe-dashboard/raw/daily/region/london.csv...\n",
      "Downloading phe-dashboard/raw/daily/region/south_east.csv...\n",
      "Downloading phe-dashboard/raw/daily/region/south_west.csv...\n",
      "Downloading phe-dashboard/raw/daily/nhsregion/north_east_yorkshire.csv...\n",
      "Downloading phe-dashboard/raw/daily/nhsregion/north_west.csv...\n",
      "Downloading phe-dashboard/raw/daily/nhsregion/midlands.csv...\n",
      "Downloading phe-dashboard/raw/daily/nhsregion/east_england.csv...\n",
      "Downloading phe-dashboard/raw/daily/nhsregion/london.csv...\n",
      "Downloading phe-dashboard/raw/daily/nhsregion/south_east.csv...\n",
      "Downloading phe-dashboard/raw/daily/nhsregion/south_west.csv...\n",
      "Downloading phe-dashboard/raw/daily/ltla/dorset.csv...\n",
      "Downloading phe-dashboard/raw/daily/ltla/bournemouth_christchurch_poole.csv...\n",
      "Downloading phe-dashboard/raw/daily/ltla/stevenage.csv...\n",
      "Downloading phe-dashboard/raw/daily/ltla/welwyn_hatfield.csv...\n",
      "Downloading phe-dashboard/raw/daily/ltla/north_hertfordshire.csv...\n",
      "Downloading phe-dashboard/raw/daily/ltla/east_hertfordshire.csv...\n",
      "Downloading phe-dashboard/raw/daily/ltla/sandwell.csv...\n",
      "Downloading phe-dashboard/raw/daily/ltla/dudley.csv...\n",
      "Downloading phe-dashboard/raw/daily/ltla/birmingham.csv...\n",
      "Downloading phe-dashboard/raw/daily/ltla/derbyshire_dales.csv...\n",
      "Downloading phe-dashboard/raw/daily/ltla/north_east_derbyshire.csv...\n",
      "Downloading phe-dashboard/raw/daily/ltla/high_peak.csv...\n",
      "Downloading phe-dashboard/raw/daily/ltla/sheffield.csv...\n",
      "Downloading phe-dashboard/raw/daily/ltla/croydon.csv...\n",
      "\n",
      "--- Downloading weekly dashboard data ---\n",
      "Downloading phe-dashboard/raw/weekly/overview/united_kingdom.csv...\n",
      "Downloading phe-dashboard/raw/weekly/nation/england.csv...\n",
      "Downloading phe-dashboard/raw/weekly/nation/scotland.csv...\n",
      "Downloading phe-dashboard/raw/weekly/nation/wales.csv...\n",
      "Downloading phe-dashboard/raw/weekly/nation/northern_ireland.csv...\n",
      "Downloading phe-dashboard/raw/weekly/region/north_east.csv...\n",
      "Downloading phe-dashboard/raw/weekly/region/north_west.csv...\n",
      "Downloading phe-dashboard/raw/weekly/region/yorkshire_humber.csv...\n",
      "Downloading phe-dashboard/raw/weekly/region/east_midlands.csv...\n",
      "Downloading phe-dashboard/raw/weekly/region/west_midlands.csv...\n",
      "Downloading phe-dashboard/raw/weekly/region/east_england.csv...\n",
      "Downloading phe-dashboard/raw/weekly/region/london.csv...\n",
      "Downloading phe-dashboard/raw/weekly/region/south_east.csv...\n",
      "Downloading phe-dashboard/raw/weekly/region/south_west.csv...\n",
      "Downloading phe-dashboard/raw/weekly/ltla/dorset.csv...\n",
      "Downloading phe-dashboard/raw/weekly/ltla/bournemouth_christchurch_poole.csv...\n",
      "Downloading phe-dashboard/raw/weekly/ltla/stevenage.csv...\n",
      "Downloading phe-dashboard/raw/weekly/ltla/welwyn_hatfield.csv...\n",
      "Downloading phe-dashboard/raw/weekly/ltla/north_hertfordshire.csv...\n",
      "Downloading phe-dashboard/raw/weekly/ltla/east_hertfordshire.csv...\n",
      "Downloading phe-dashboard/raw/weekly/ltla/sandwell.csv...\n",
      "Downloading phe-dashboard/raw/weekly/ltla/dudley.csv...\n",
      "Downloading phe-dashboard/raw/weekly/ltla/birmingham.csv...\n",
      "Downloading phe-dashboard/raw/weekly/ltla/derbyshire_dales.csv...\n",
      "Downloading phe-dashboard/raw/weekly/ltla/north_east_derbyshire.csv...\n",
      "Downloading phe-dashboard/raw/weekly/ltla/high_peak.csv...\n",
      "Downloading phe-dashboard/raw/weekly/ltla/sheffield.csv...\n",
      "Downloading phe-dashboard/raw/weekly/ltla/croydon.csv...\n",
      "\n",
      "--- Downloading surveillance data ---\n",
      "\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    print(\"--- Downloading daily dashboard data ---\")\n",
    "    for areaType, areaNames in phe_core.areas:\n",
    "        for areaName in areaNames:\n",
    "            area = AreaDownload(areaType, areaName)\n",
    "            area.downloadDaily()\n",
    "\n",
    "    print(\"\\n--- Downloading weekly dashboard data ---\")\n",
    "    for areaType, areaNames in phe_core.areas:\n",
    "        for areaName in areaNames:\n",
    "            area = AreaDownload(areaType, areaName)\n",
    "            area.downloadWeekly()\n",
    "\n",
    "    print(\"\\n--- Downloading surveillance data ---\")\n",
    "    downloadSurveillance()\n",
    "\n",
    "    print(\"\\nAll done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
