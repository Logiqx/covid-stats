{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONS Charts\n",
    "\n",
    "Created by Michael George (AKA Logiqx)\n",
    "\n",
    "Website: https://logiqx.github.io/covid-stats/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Standard python libraries plus determination of projdir, basic printable class, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "import unittest\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as tck\n",
    "\n",
    "import common_core\n",
    "import ons_core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy Helper Functions\n",
    "\n",
    "Useful functionality such as moving average or rolling sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shiftRegistrations(data):\n",
    "    \"\"\"Shift registration data left by half a period\"\"\"\n",
    "    \n",
    "    # Final value is invalid (so not included in the convolution result) and needs to be zero\n",
    "    result = np.append(np.convolve(data, np.array([0.5, 0.5]), mode=\"valid\"), 0)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "class TestShiftRegistrations(unittest.TestCase):\n",
    "    '''Class to test rollingSum function'''   \n",
    "\n",
    "    def testShift(self):\n",
    "        '''Test processing of a list shorter than the window size'''\n",
    "\n",
    "        actual = shiftRegistrations(np.arange(6))\n",
    "        expected = np.array([0.5, 1.5, 2.5, 3.5, 4.5, 0])\n",
    "\n",
    "        self.assertEqual((actual == expected).all(), True)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEstimatedOccurrences(cache):\n",
    "    \"\"\"Calculate missing values in cache\"\"\"\n",
    "\n",
    "    estimates = {}\n",
    "    \n",
    "    # Use the ONS occurrences for England and Wales\n",
    "    masterArea = common_core.ENGLAND_WALES\n",
    "\n",
    "    # Simple references to the registrations and occurrences ofthe master area\n",
    "    knownRegistrations = shiftRegistrations(cache[masterArea][ons_core.TOTAL_REGISTRATIONS])\n",
    "    knownOccurrences = cache[masterArea][ons_core.TOTAL_OCCURRENCES]\n",
    "\n",
    "    # Run this process for all regions and nations other than the master area\n",
    "    for areaName in common_core.regionNames + common_core.nationNames:\n",
    "        if areaName != masterArea and areaName in cache:\n",
    "            \n",
    "            # TODO - remove COVID deaths before doing calculation\n",
    "\n",
    "            # Shift registrations left by half a week\n",
    "            shiftedRegistrations = shiftRegistrations(cache[areaName][ons_core.TOTAL_REGISTRATIONS])\n",
    "\n",
    "            # Estimate occurrences using a simple percentage of the known occurrences\n",
    "            estimatedOccurrences = knownOccurrences * np.divide(shiftedRegistrations, knownRegistrations,\n",
    "                                      out=np.zeros_like(shiftedRegistrations), where=knownRegistrations != 0)\n",
    "            \n",
    "            # Locate the last week in the cache where total_occurrences is populated\n",
    "            cacheIdx = np.where(cache[areaName][ons_core.TOTAL_OCCURRENCES] > 0)[0][-1]\n",
    "            \n",
    "            # Patch subsequent data using the estimates\n",
    "            cache[areaName][cacheIdx + 1:][ons_core.TOTAL_OCCURRENCES] = estimatedOccurrences[cacheIdx + 1:]\n",
    "            \n",
    "            # Maintain a cache of estimates for testing purpopses\n",
    "            estimates[areaName] = estimatedOccurrences\n",
    "            \n",
    "    return estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateErrors(cache, estimates):\n",
    "    \"\"\"Calculate estimation errors\"\"\"\n",
    "\n",
    "    masterArea = common_core.ENGLAND_WALES\n",
    "\n",
    "    for areaName in common_core.regionNames + common_core.nationNames:\n",
    "        if areaName in cache and areaName != masterArea:\n",
    "            print(f\"{areaName}:\")\n",
    "            \n",
    "            totalPctMAE = 0\n",
    "        \n",
    "            years = range(2010, 2018)\n",
    "            \n",
    "            for year in years:\n",
    "                startDate = f\"{year}-01-01\"\n",
    "                stopDate = f\"{year}-12-31\"\n",
    "\n",
    "                areaData = cache[areaName]\n",
    "\n",
    "                startIdx = np.where(areaData[ons_core.WEEK_ENDED] >= startDate)[0][0]\n",
    "                stopIdx = np.where(areaData[ons_core.WEEK_ENDED] < stopDate)[0][-1]\n",
    "\n",
    "                pctMAE = 100 * np.average(np.abs(areaData[startIdx:stopIdx][ons_core.TOTAL_OCCURRENCES] -\n",
    "                                            areaData[startIdx:stopIdx][ons_core.TOTAL_REGISTRATIONS].astype(np.float64)) /\n",
    "                                        areaData[startIdx:stopIdx][ons_core.TOTAL_OCCURRENCES])\n",
    "\n",
    "                pctMAE = 100 * np.average(np.abs(areaData[startIdx:stopIdx][ons_core.TOTAL_OCCURRENCES] -\n",
    "                                            shiftRegistrations(areaData[startIdx:stopIdx][ons_core.TOTAL_REGISTRATIONS])) /\n",
    "                                        areaData[startIdx:stopIdx][ons_core.TOTAL_OCCURRENCES])\n",
    "\n",
    "                pctMAE = 100 * np.average(np.abs(areaData[startIdx:stopIdx][ons_core.TOTAL_OCCURRENCES] -\n",
    "                                            estimates[areaName][startIdx:stopIdx]) /\n",
    "                                        areaData[startIdx:stopIdx][ons_core.TOTAL_OCCURRENCES])\n",
    "\n",
    "                totalPctMAE += pctMAE\n",
    "                \n",
    "                print(f\"{year} = {pctMAE:.2f}%\")\n",
    "\n",
    "            print(f\"Avg  = {totalPctMAE / len(years):.2f}%\")\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Data\n",
    "\n",
    "Simple plots of ONS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prunePoints(x_points, y_points):\n",
    "    '''Remove leading and trailing zeros'''\n",
    "\n",
    "    match = np.where(y_points > 0)[0]\n",
    "\n",
    "    if len(match) > 0:\n",
    "        start = match[0]\n",
    "        end = match[-1]\n",
    "    else:\n",
    "        start = 0\n",
    "        end = -1\n",
    "        \n",
    "    return x_points[start:end + 1], y_points[start:end + 1]\n",
    "    \n",
    "\n",
    "def plotRegion(cache, minimums, maximums, averages, areaName, fields, fig, ax, startDate=None, stopDate=None):\n",
    "    '''Plot data for visual inspection'''\n",
    "    \n",
    "    areaData = cache[areaName]\n",
    "\n",
    "    ax.set_title(f\"Weekly Deaths in {areaName}\\nShown by date of occurrence\")\n",
    "    ax.set_ylabel('Number of deaths')\n",
    "\n",
    "    # Determine which rows need to be plotted\n",
    "    startIdx = np.where(areaData[ons_core.WEEK_ENDED] >= startDate)[0][0]\n",
    "    stopIdx = np.where(areaData[ons_core.WEEK_ENDED] < stopDate)[0][-1]\n",
    "\n",
    "    xMin = yMin = stopIdx\n",
    "    xMax = yMax = 0\n",
    "    \n",
    "    for field in fields:\n",
    "        y_points = areaData[field[\"name\"]][startIdx:stopIdx + 1]\n",
    "        x_points = np.arange(len(y_points))       \n",
    "        x_points, y_points = prunePoints(x_points, y_points)\n",
    "        ax.plot(x_points, y_points, label = field[\"label\"], color=field[\"color\"], linestyle=field[\"linestyle\"])\n",
    "        if len(x_points) > 0:\n",
    "            xMin = min(xMin, min(x_points))\n",
    "            yMin = min(yMin, min(y_points))\n",
    "            xMax = max(xMax, max(x_points))\n",
    "            yMax = max(yMax, max(y_points))\n",
    "\n",
    "    y_points = averages[areaName][startIdx:stopIdx + 1]\n",
    "    x_points = np.arange(len(y_points))       \n",
    "    x_points, y_points = prunePoints(x_points, y_points)\n",
    "    ax.plot(x_points, y_points, label = \"averages\", color=\"navy\", linestyle=\"dotted\")\n",
    "    if len(x_points) > 0:\n",
    "        xMin = min(xMin, min(x_points))\n",
    "        yMin = min(yMin, min(y_points))\n",
    "        xMax = max(xMax, max(x_points))\n",
    "        yMax = max(yMax, max(y_points))\n",
    "\n",
    "    y1_points = minimums[areaName][startIdx:stopIdx + 1]\n",
    "    y2_points = maximums[areaName][startIdx:stopIdx + 1]\n",
    "    x_points = np.arange(len(y1_points))       \n",
    "    x_points, y1_points = prunePoints(x_points, y1_points)\n",
    "    x_points = np.arange(len(y2_points))       \n",
    "    x_points, y2_points = prunePoints(x_points, y2_points)\n",
    "    ax.fill_between(x_points, y1_points, y2_points, label = \"range\", color=\"lightsteelblue\")\n",
    "    if len(x_points) > 0:\n",
    "        xMin = min(xMin, min(x_points))\n",
    "        yMin = min(yMin, min(y_points))\n",
    "        xMax = max(xMax, max(x_points))\n",
    "        yMax = max(yMax, max(y_points))\n",
    "\n",
    "    # Determine y-axis labelling\n",
    "    yMax *= 1.1\n",
    "    if yMax > 10000:\n",
    "        interval = yMax // 10 // 1000 * 1000\n",
    "    elif yMax > 1000:\n",
    "        interval = yMax // 10 // 100 * 100\n",
    "    else:\n",
    "        interval = yMax // 10\n",
    "\n",
    "    ax.set_ylim(ymin=0, ymax=yMax)\n",
    "    ax.set_yticks(np.arange(0, yMax, interval))\n",
    "    ax.get_yaxis().set_major_formatter(tck.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "\n",
    "    # Determine x-axis labelling\n",
    "    xticks = np.array(areaData[ons_core.WEEK_ENDED])[startIdx:stopIdx + 1]\n",
    "    tickInterval = (stopIdx - startIdx) // 52\n",
    "    if tickInterval == 0:\n",
    "        tickInterval = 1\n",
    "\n",
    "    ax.set_xlim(xmin=xMin - (xMin - ax.get_xlim()[0]) / 5, xmax=xMax + (ax.get_xlim()[1] - xMax) / 5)\n",
    "    ax.set_xticks(np.arange(0, len(xticks), tickInterval))\n",
    "    ax.set_xticklabels(xticks[::tickInterval], rotation=90)\n",
    "\n",
    "    lastDate = datetime.strptime(areaData[ons_core.WEEK_ENDED][stopIdx], \"%Y-%m-%d\").strftime(\"%A %-d %B %Y\")\n",
    "\n",
    "    textStr = f'n.b. This only shows deaths occurring before {lastDate}'\n",
    "    ax.text(0.5, 0.88, textStr, transform=ax.transAxes, horizontalalignment='center', verticalalignment='top')\n",
    "\n",
    "    #textStr = 'Sources: Office for National Statistics\\nPublic Health England'\n",
    "    textStr = 'Source: Office for National Statistics'\n",
    "    ax.text(0.98, 0.04, textStr, transform=ax.transAxes, horizontalalignment='right', verticalalignment='bottom')\n",
    "\n",
    "    textStr = f'Created {datetime.now().strftime(\"%d %b\")}\\n@Mike_aka_Logiqx'\n",
    "    ax.text(0.02, 0.04, textStr, transform=ax.transAxes, horizontalalignment='left', verticalalignment='bottom')\n",
    "\n",
    "    ax.legend(loc = 'upper center', ncol=3)\n",
    "\n",
    "\n",
    "def plotRegions(cache, minimums, maximums, averages, areaNames, startDate=None, stopDate=None):\n",
    "    '''Plot data for visual inspection'''\n",
    "    \n",
    "    fig, axs = plt.subplots(len(areaNames), figsize=(16, 6 * len(areaNames)), dpi=150)\n",
    "    \n",
    "    fields = [\n",
    "        {\n",
    "            \"name\": ons_core.TOTAL_OCCURRENCES,\n",
    "            \"label\": \"Total Occurrences\",\n",
    "            \"color\": \"navy\",\n",
    "            \"linestyle\": \"solid\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    disabled = [\n",
    "        {\n",
    "            \"name\": ons_core.TOTAL_REGISTRATIONS,\n",
    "            \"label\": \"Total Registrations\",\n",
    "            \"color\": \"cornflowerblue\",\n",
    "            \"linestyle\": \"dotted\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": ons_core.COVID_OCCURRENCES,\n",
    "            \"label\": \"COVID-19 Occurrences\",\n",
    "            \"color\": \"red\",\n",
    "            \"linestyle\": \"solid\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": ons_core.COVID_REGISTRATIONS,\n",
    "            \"label\": \"COVID-19 Registrations\",\n",
    "            \"color\": \"lightcoral\",\n",
    "            \"linestyle\": \"dotted\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    for i in range(len(areaNames)):\n",
    "        areaName = areaNames[i]\n",
    "        areaData = cache[areaName]\n",
    "\n",
    "        if len(areaNames) == 1:\n",
    "            plotRegion(cache, minimums, maximums, averages, areaName, fields, fig, axs, startDate=startDate, stopDate=stopDate)\n",
    "        else:\n",
    "            plotRegion(cache, minimums, maximums, averages, areaName, fields, fig, axs[i], startDate=startDate, stopDate=stopDate)\n",
    "\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    plt.show(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    cache = ons_core.loadCsvFiles(ons_core.ONS_DEATHS, \"weekly\", verbose = False)\n",
    "    \n",
    "    estimates = getEstimatedOccurrences(cache)\n",
    "\n",
    "    #calculateErrors(cache, estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateAverages(cache):\n",
    "    \"\"\"Calculate 5 year averages and ranges\"\"\"\n",
    "\n",
    "    minimums = {}\n",
    "    maximums = {}\n",
    "    averages = {}\n",
    "    \n",
    "    for areaName in list(cache.keys()):\n",
    "\n",
    "        tmpMin = np.array([], dtype=\"u4\")\n",
    "        tmpMax = np.array([], dtype=\"u4\")\n",
    "        tmpAvg = np.array([])\n",
    "        \n",
    "        yearIdx = np.where(cache[areaName][ons_core.WEEK_NUMBER] == 1)[0]\n",
    "\n",
    "        for i in range(5, len(yearIdx)):\n",
    "\n",
    "            if i == len(yearIdx) - 1:\n",
    "                numWeeks = len(cache[areaName]) - yearIdx[i]\n",
    "            else:\n",
    "                numWeeks = yearIdx[i + 1] - yearIdx[i]\n",
    "\n",
    "            grid = np.vstack([\n",
    "                cache[areaName][yearIdx[i - 5]:yearIdx[i - 5] + numWeeks][ons_core.TOTAL_OCCURRENCES],\n",
    "                cache[areaName][yearIdx[i - 4]:yearIdx[i - 4] + numWeeks][ons_core.TOTAL_OCCURRENCES],\n",
    "                cache[areaName][yearIdx[i - 3]:yearIdx[i - 3] + numWeeks][ons_core.TOTAL_OCCURRENCES],\n",
    "                cache[areaName][yearIdx[i - 2]:yearIdx[i - 2] + numWeeks][ons_core.TOTAL_OCCURRENCES],\n",
    "                cache[areaName][yearIdx[i - 1]:yearIdx[i - 1] + numWeeks][ons_core.TOTAL_OCCURRENCES]\n",
    "            ])\n",
    "\n",
    "            tmpMin = np.append(tmpMin, np.min(grid, axis = 0))\n",
    "            tmpMax = np.append(tmpMax, np.max(grid, axis = 0))\n",
    "            tmpAvg = np.append(tmpAvg, np.average(grid, axis = 0))\n",
    "        \n",
    "        minimums[areaName] = np.concatenate((np.zeros(yearIdx[5], dtype=\"u4\"), tmpMin))\n",
    "        maximums[areaName] = np.concatenate((np.zeros(yearIdx[5], dtype=\"u4\"), tmpMax))\n",
    "        averages[areaName] = np.concatenate((np.zeros(yearIdx[5]), tmpAvg))\n",
    "        \n",
    "    return minimums, maximums, averages\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    minimums, maximums, averages = calculateAverages(cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    areaNames = [\"England and Wales\", \"England\", \"Wales\"]\n",
    "    areaNames = [\"West Midlands\", \"East Midlands\", \"South West\"]\n",
    "    areaNames = [\"North West\", \"North East\", \"Yorkshire and The Humber\"]\n",
    "    areaNames = [\"London\", \"East of England\", \"South East\"]\n",
    "\n",
    "    # Check heatwave of August 2003 - https://www.eurosurveillance.org/content/10.2807/esm.10.07.00558-en\n",
    "    startDate = '2003-07-01'\n",
    "    stopDate = '2003-09-01'\n",
    "\n",
    "    # Show reg delays\n",
    "    startDate = date(2010, 1, 1).strftime('%Y-%m-%d')\n",
    "    stopDate = date(2020, 1, 8)\n",
    "\n",
    "    # Last X years\n",
    "    startDate = (date(2021, 1, 15) - timedelta(weeks = 52 * 10)).strftime('%Y-%m-%d')\n",
    "    stopDate = date(2021, 1, 15).strftime('%Y-%m-%d')\n",
    "\n",
    "    # Same range as error check\n",
    "    #startDate = '2014-01-01'\n",
    "    #stopDate = '2018-12-31'\n",
    "    \n",
    "    plotRegions(cache, minimums, maximums, averages, areaNames, startDate=startDate, stopDate=stopDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
