{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common Core\n",
    "\n",
    "Created by Michael George (AKA Logiqx)\n",
    "\n",
    "Website: https://logiqx.github.io/covid-stats/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "import unittest\n",
    "\n",
    "import urllib.request\n",
    "import urllib.parse\n",
    "import re\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "projdir = os.path.realpath(os.path.join(sys.path[0], \"..\"))\n",
    "dataDir = os.path.join(projdir, \"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Definitions\n",
    "\n",
    "e.g. Nation and region names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 7 nations in the UK\n",
    "nations = \\\n",
    "{\n",
    "    \"K02000001\": \"United Kingdom\",\n",
    "    \"K03000001\": \"Great Britain\",\n",
    "    \"K04000001\": \"England and Wales\",\n",
    "    \"E92000001\": \"England\",\n",
    "    \"W92000004\": \"Wales\",\n",
    "    \"S92000003\": \"Scotland\",\n",
    "    \"N92000002\": \"Northern Ireland\"\n",
    "}\n",
    "nationNames = [*nations.values()]\n",
    "\n",
    "UNITED_KINGDOM = nations[\"K02000001\"]\n",
    "GREAT_BRITAIN = nations[\"K03000001\"]\n",
    "ENGLAND_WALES = nations[\"K04000001\"]\n",
    "ENGLAND = nations[\"E92000001\"]\n",
    "WALES = nations[\"W92000004\"]\n",
    "SCOTLAND = nations[\"S92000003\"]\n",
    "NORTHERN_IRELAND = nations[\"N92000002\"]\n",
    "\n",
    "# Some data sources such as the ONS daily occurrences do not use the standard nation codes\n",
    "nationMappings = \\\n",
    "{\n",
    "    \"W99999999\": \"W92000004\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are 9 regions in England\n",
    "regions = \\\n",
    "{\n",
    "    \"E12000001\": \"North East\",\n",
    "    \"E12000002\": \"North West\",\n",
    "    \"E12000003\": \"Yorkshire and The Humber\",\n",
    "    \"E12000004\": \"East Midlands\",\n",
    "    \"E12000005\": \"West Midlands\",\n",
    "    \"E12000006\": \"East of England\",\n",
    "    \"E12000007\": \"London\",\n",
    "    \"E12000008\": \"South East\",\n",
    "    \"E12000009\": \"South West\"\n",
    "}\n",
    "regionNames = [*regions.values()]\n",
    "\n",
    "# There are some common aliases for regions in England\n",
    "regionAliases = {\n",
    "    \"East of England\": [\"East\"]    # Used by historical ONS deaths data\n",
    "}\n",
    "\n",
    "# There are 7 NHS regions in England\n",
    "nhsRegionNames = \\\n",
    "[\n",
    "    \"North East and Yorkshire\",\n",
    "    \"North West\",\n",
    "    \"Midlands\",\n",
    "    \"East of England\",\n",
    "    \"London\",\n",
    "    \"South East\",\n",
    "    \"South West\"\n",
    "]\n",
    "\n",
    "# Mapping of regions to NHS regions\n",
    "nhsRegionMappings = \\\n",
    "{\n",
    "    \"North East\": \"North East and Yorkshire\",\n",
    "    \"North West\": \"North West\",\n",
    "    \"Yorkshire and The Humber\": \"North East and Yorkshire\",\n",
    "    \"East Midlands\": \"Midlands\",\n",
    "    \"West Midlands\": \"Midlands\",\n",
    "    \"East of England\": \"East of England\",\n",
    "    \"London\": \"London\",\n",
    "    \"South East\": \"South East\",\n",
    "    \"South West\": \"South West\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateFieldNames = [\"week_ended\", \"date\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printable Class\n",
    "\n",
    "Simple class that allows other classes to be printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Printable:\n",
    "    def __repr__(self):\n",
    "        return str(self.__class__) + \": \" + str(self.__dict__)\n",
    "\n",
    "    def __str__(self):\n",
    "        return str(self.__class__) + \": \" + str(self.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Functions\n",
    "\n",
    "Useful functions such as modifying area names for use as filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSafeName(areaName):\n",
    "    \"\"\"Return area name suitable for use in filenames\"\"\"\n",
    "\n",
    "    for word in 'of', 'and', 'the', 'The', '+':\n",
    "        areaName = areaName.replace(' ' + word + ' ', ' ')\n",
    "\n",
    "    areaName = areaName.lower().replace(' ', '_').replace(',', '')\n",
    "\n",
    "    return areaName\n",
    "\n",
    "\n",
    "def getPartName(fileName):\n",
    "    \"\"\"Get the part of the filename which is relative to the data directory\"\"\"\n",
    "    \n",
    "    partName = fileName.replace(dataDir, \"\")[1:]\n",
    "    \n",
    "    return partName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestGetSafeName(unittest.TestCase):\n",
    "    '''Class to test getSafeName function'''   \n",
    "\n",
    "    def test_of(self):\n",
    "        '''Test use of the word \"of\"'''\n",
    "        self.assertEqual(getSafeName('East of England'), 'east_england')\n",
    "\n",
    "    def test_and(self):\n",
    "        '''Test use of the words \"and\"'''\n",
    "        self.assertEqual(getSafeName('England and Wales'), 'england_wales')\n",
    "        self.assertEqual(getSafeName('North East and Yorkshire'), 'north_east_yorkshire')\n",
    "\n",
    "    def test_and_the(self):\n",
    "        '''Test use of the words \"and\" + \"the\"'''\n",
    "        self.assertEqual(getSafeName('Yorkshire and the Humber'), 'yorkshire_humber')\n",
    "        self.assertEqual(getSafeName('Yorkshire and The Humber'), 'yorkshire_humber')\n",
    "\n",
    "    def test_lists(self):\n",
    "        '''Test use of the seperator \",\" + word \"and\"'''\n",
    "        self.assertEqual(getSafeName('Bournemouth, Christchurch and Poole'), 'bournemouth_christchurch_poole')\n",
    "\n",
    "    def test_plus(self):\n",
    "        '''Test use of the \"+\" symbol'''\n",
    "        self.assertEqual(getSafeName('England + Wales'), 'england_wales')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOnsWeek(dt):\n",
    "    \"\"\"Simple function to get the ONS year, week and day\"\"\"\n",
    "\n",
    "    # Shifting by 2 days allows us to use isocalendar() but for weeks ending on Friday\n",
    "    shifted = dt + timedelta(days=2)\n",
    "\n",
    "    return shifted.isocalendar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestGetOnsWeek(unittest.TestCase):\n",
    "    '''Class to test getOnsWeek function'''   \n",
    "\n",
    "    def test_w1_d7(self):\n",
    "        '''Test week 1 day 7'''\n",
    "        self.assertEqual(getOnsWeek(date(2011, 1, 7)), (2011, 1, 7))\n",
    "        self.assertEqual(getOnsWeek(date(2012, 1, 6)), (2012, 1, 7))\n",
    "        self.assertEqual(getOnsWeek(date(2013, 1, 4)), (2013, 1, 7))\n",
    "        self.assertEqual(getOnsWeek(date(2014, 1, 3)), (2014, 1, 7))\n",
    "        self.assertEqual(getOnsWeek(date(2015, 1, 2)), (2015, 1, 7))\n",
    "        self.assertEqual(getOnsWeek(date(2016, 1, 8)), (2016, 1, 7))\n",
    "        self.assertEqual(getOnsWeek(date(2017, 1, 6)), (2017, 1, 7))\n",
    "        self.assertEqual(getOnsWeek(date(2018, 1, 5)), (2018, 1, 7))\n",
    "        self.assertEqual(getOnsWeek(date(2019, 1, 4)), (2019, 1, 7))\n",
    "        self.assertEqual(getOnsWeek(date(2020, 1, 3)), (2020, 1, 7))\n",
    "        self.assertEqual(getOnsWeek(date(2021, 1, 8)), (2021, 1, 7))\n",
    "\n",
    "    def test_w1_d1(self):\n",
    "        '''Test week 1 day 1'''\n",
    "        self.assertEqual(getOnsWeek(date(2011, 1, 1)),   (2011, 1, 1))\n",
    "        self.assertEqual(getOnsWeek(date(2011, 12, 31)), (2012, 1, 1))\n",
    "        self.assertEqual(getOnsWeek(date(2012, 12, 29)), (2013, 1, 1))\n",
    "        self.assertEqual(getOnsWeek(date(2013, 12, 28)), (2014, 1, 1))\n",
    "        self.assertEqual(getOnsWeek(date(2014, 12, 27)), (2015, 1, 1))\n",
    "        self.assertEqual(getOnsWeek(date(2016, 1, 2)),   (2016, 1, 1))\n",
    "        self.assertEqual(getOnsWeek(date(2016, 12, 31)), (2017, 1, 1))\n",
    "        self.assertEqual(getOnsWeek(date(2017, 12, 30)), (2018, 1, 1))\n",
    "        self.assertEqual(getOnsWeek(date(2018, 12, 29)), (2019, 1, 1))\n",
    "        self.assertEqual(getOnsWeek(date(2019, 12, 28)), (2020, 1, 1))\n",
    "        self.assertEqual(getOnsWeek(date(2021, 1, 2)),   (2021, 1, 1))\n",
    "\n",
    "    def test_w52_d7(self):\n",
    "        '''Test week 1 day 1'''\n",
    "        self.assertEqual(getOnsWeek(date(2010, 12, 31)), (2010, 52, 7))\n",
    "        self.assertEqual(getOnsWeek(date(2011, 12, 30)), (2011, 52, 7))\n",
    "        self.assertEqual(getOnsWeek(date(2012, 12, 28)), (2012, 52, 7))\n",
    "        self.assertEqual(getOnsWeek(date(2013, 12, 27)), (2013, 52, 7))\n",
    "        self.assertEqual(getOnsWeek(date(2014, 12, 26)), (2014, 52, 7))\n",
    "        self.assertEqual(getOnsWeek(date(2016, 1, 1)),   (2015, 53, 7))\n",
    "        self.assertEqual(getOnsWeek(date(2016, 12, 30)), (2016, 52, 7))\n",
    "        self.assertEqual(getOnsWeek(date(2017, 12, 29)), (2017, 52, 7))\n",
    "        self.assertEqual(getOnsWeek(date(2018, 12, 28)), (2018, 52, 7))\n",
    "        self.assertEqual(getOnsWeek(date(2019, 12, 27)), (2019, 52, 7))\n",
    "        self.assertEqual(getOnsWeek(date(2021, 1, 1)),   (2020, 53, 7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Functions\n",
    "\n",
    "Download spreadsheets by parsing the HTML for suitable links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipExisting = True\n",
    "skipHistory = False\n",
    "\n",
    "class WebDownload():\n",
    "\n",
    "    def __init__(self, skipExisting=skipExisting, skipHistory=skipHistory, verbose=verbose):\n",
    "        \"\"\"Initialisise the area object\"\"\"\n",
    "\n",
    "        self.skipExisting, self.skipHistory, self.verbose = skipExisting, skipHistory, verbose\n",
    "        self.downloaded = {}\n",
    "        \n",
    "        \n",
    "    def downloadFile(self, url, rawDir, subDir):\n",
    "        \"\"\"Download a binary file from the URL provided\"\"\"\n",
    "\n",
    "        baseName = os.path.basename(url)\n",
    "        dirName = os.path.join(rawDir, subDir)\n",
    "        fileName = os.path.join(dirName, baseName)\n",
    "\n",
    "        partName = getPartName(fileName)\n",
    "\n",
    "        if (os.path.exists(fileName) or baseName in self.downloaded) and self.skipExisting:\n",
    "            if self.verbose:\n",
    "                print(f\"Skipping download of {partName}...\")\n",
    "        else:\n",
    "            print(f\"Downloading {partName}...\")\n",
    "\n",
    "            # Ensure raw path exists\n",
    "            if not os.path.exists(dirName):\n",
    "                os.makedirs(dirName)\n",
    "\n",
    "            req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla'})\n",
    "            response = urllib.request.urlopen(req, timeout=60)\n",
    "\n",
    "            with open(fileName, \"wb\") as outfile:\n",
    "                chunk = response.read(4096)\n",
    "                while chunk:\n",
    "                    outfile.write(chunk)\n",
    "                    chunk = response.read(4096)\n",
    "\n",
    "            response.close()\n",
    "\n",
    "        if baseName not in self.downloaded:\n",
    "            self.downloaded[baseName] = partName\n",
    "\n",
    "\n",
    "    def downloadFiles(self, rawDir, url, patterns, category=None):\n",
    "\n",
    "        req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla'})\n",
    "        response = urllib.request.urlopen(req, timeout=15)\n",
    "\n",
    "        soup = BeautifulSoup(response, \"lxml\")\n",
    "        anchors = soup.find_all(\"a\")\n",
    "\n",
    "        response.close()\n",
    "\n",
    "        done = False\n",
    "\n",
    "        for anchor in anchors:\n",
    "            href = anchor.get(\"href\")\n",
    "\n",
    "            for pattern in patterns:\n",
    "                if re.search(pattern[1], href):\n",
    "                    url = urllib.parse.urljoin(url, href)\n",
    "\n",
    "                    if category:\n",
    "                        subDir = os.path.join(pattern[0], category)\n",
    "                    else:\n",
    "                        subDir = pattern[0]\n",
    "\n",
    "                    self.downloadFile(url, rawDir, subDir)\n",
    "\n",
    "                    if self.skipHistory:\n",
    "                        done = True\n",
    "                        \n",
    "            if done:\n",
    "                break\n",
    "                        \n",
    "        return list(self.downloaded.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CSV into NumPy Array\n",
    "\n",
    "SImple function to load data from CSV into an ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCsvIntoArray(fileName, verbose=verbose):\n",
    "    '''Load CSV file into numpy array'''\n",
    "\n",
    "    if verbose:\n",
    "        partName = getPartName(fileName)\n",
    "\n",
    "        print(f\"Loading {partName}...\")\n",
    "\n",
    "    try:\n",
    "        with open(fileName, 'r') as f:\n",
    "            reader = csv.reader(f, delimiter = ',')\n",
    "\n",
    "            dtype = []\n",
    "            converters = {}\n",
    "            colNames = next(reader)\n",
    "\n",
    "            for i in range(len(colNames)):\n",
    "                colName = colNames[i]\n",
    "                if colName in dateFieldNames:\n",
    "                    dtype.append((colName, \"U10\"))\n",
    "                else:\n",
    "                    dtype.append((colName, \"u4\"))\n",
    "                    converters[i] = lambda s: int(s or 0)\n",
    "\n",
    "            data = np.genfromtxt(f, dtype=dtype, converters=converters, delimiter=\",\")\n",
    "\n",
    "    except:\n",
    "        print(f\"Failed to load {fileName}\")\n",
    "        raise\n",
    "        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NumPy Helper Functions\n",
    "\n",
    "Useful functionality such as moving average or rolling sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollingSum(data, window=7):\n",
    "    \"\"\"Calculate rolling sum using linear convolution\"\"\"\n",
    "    \n",
    "    # The mode \"full\" results in the more values than required, hence the len(data)\n",
    "    # The result should also match the original data, hence the astype()\n",
    "    result = np.convolve(data, np.ones(window), mode=\"full\")[:len(data)].astype(data.dtype) \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestRollingSum(unittest.TestCase):\n",
    "    '''Class to test rollingSum function'''   \n",
    "\n",
    "    def testShortList(self):\n",
    "        '''Test processing of a list shorter than the window size'''\n",
    "\n",
    "        actual = rollingSum(np.arange(6), 7)\n",
    "        expected = np.array([0, 1, 3, 6, 10, 15])\n",
    "\n",
    "        self.assertEqual((actual == expected).all(), True)\n",
    "\n",
    "\n",
    "    def testLongerList(self):\n",
    "        '''Test processing of a list longer than the window size'''\n",
    "\n",
    "        actual = rollingSum(np.arange(14), 7)\n",
    "        expected = np.array([0, 1, 3, 6, 10, 15, 21, 28, 35, 42, 49, 56, 63, 70])\n",
    "\n",
    "        self.assertEqual((actual == expected).all(), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movingAverage(data, window=7):\n",
    "    \"\"\"Calculate moving average using linear convolution\"\"\"\n",
    "\n",
    "    # Only use convolution if the input is at least as long as the window size\n",
    "    if len(data) >= window:\n",
    "        # The mode \"valid\" results in the less values than required, hence the np.zeros()\n",
    "        result = np.concatenate((np.zeros(window // 2),\n",
    "                                 np.convolve(data, np.ones(window) / window, mode=\"valid\"),\n",
    "                                 np.zeros(window // 2)))\n",
    "\n",
    "    else:\n",
    "        # Result is a simple ndarray of zeros\n",
    "        result = np.zeros(len(data))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestMovingAverage(unittest.TestCase):\n",
    "    '''Class to test rollingSum function'''   \n",
    "\n",
    "    def testShortList(self):\n",
    "        '''Test processing of a list shorter than the window size'''\n",
    "\n",
    "        actual = movingAverage(np.arange(6), 7)\n",
    "        expected = np.array(np.zeros(6))\n",
    "\n",
    "        self.assertEqual((actual == expected).all(), True)\n",
    "\n",
    "\n",
    "    def testLongerList(self):\n",
    "        '''Test processing of a list longer than the window size'''\n",
    "\n",
    "        actual = movingAverage(np.arange(14), 7)\n",
    "        expected = np.array([0, 0, 0, 3, 4, 5, 6, 7, 8, 9, 10, 0, 0, 0])\n",
    "\n",
    "        # Comparison of floating point values must be approximate\n",
    "        self.assertEqual((abs(actual - expected) < 1e-10).all(), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Galleries\n",
    "\n",
    "Page + Gallery + Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IndexPage(Printable):\n",
    "    \"\"\"Simple class to create HTML index page\"\"\"\n",
    "\n",
    "    def __init__(self, fileName, details):\n",
    "\n",
    "        self.fileName = fileName\n",
    "        self.details = details\n",
    "\n",
    "        self.galleries = {}\n",
    "        \n",
    "        # Determine relative path to \"docs\" folder\n",
    "        docsPath = \"\"\n",
    "        tmpPath = os.path.dirname(fileName)\n",
    "        while os.path.basename(tmpPath) != \"docs\":\n",
    "            if docsPath:\n",
    "                docsPath += \"/\"\n",
    "            docsPath += \"..\"\n",
    "            tmpPath = os.path.dirname(tmpPath)           \n",
    "        self.details[\"DOCS_PATH\"] = docsPath\n",
    "\n",
    "    \n",
    "    def addGallery(self, galleryId, details):\n",
    "        \"\"\"Add a new gallery to the index page\"\"\"\n",
    "\n",
    "        self.galleries[galleryId] = IndexGallery(details)\n",
    "        \n",
    "        return self.galleries[galleryId]\n",
    "\n",
    "\n",
    "    def getHtml(self):\n",
    "        \"\"\"Get the final HTML using the templates\"\"\"\n",
    "\n",
    "        template = os.path.join(projdir, \"docs\", \"template\", \"main.template.html\")\n",
    "        with open(template, 'r') as f:\n",
    "            html = f.read()\n",
    "\n",
    "        for detail in self.details:\n",
    "            html = html.replace(\"{\" + f\"{detail}\" + \"}\", self.details[detail])\n",
    "\n",
    "        galleriesHtml = \"\"\n",
    "        for galleryId in self.galleries:\n",
    "            galleriesHtml += self.galleries[galleryId].getHtml() + \"\\n\"\n",
    "\n",
    "        html = html.replace(\"{GALLERY_TEMPLATES}\\n\", galleriesHtml)\n",
    "\n",
    "        return html\n",
    "\n",
    "\n",
    "    def saveHtml(self):\n",
    "        \"\"\"Save the final HTML to disk\"\"\"\n",
    "\n",
    "        html = self.getHtml()\n",
    "\n",
    "        with open(self.fileName, 'w') as f:\n",
    "            f.write(html)\n",
    "\n",
    "        return html\n",
    "\n",
    "\n",
    "class IndexGallery(Printable):\n",
    "    \"\"\"Simple class to create HTML gallery\"\"\"\n",
    "\n",
    "    def __init__(self, details):\n",
    "\n",
    "        self.details = details\n",
    "\n",
    "        self.figures = {}\n",
    "\n",
    "    \n",
    "    def addFigure(self, figureId, relPath, fileName, details):\n",
    "        \"\"\"Add a new figure to the gallery\"\"\"\n",
    "\n",
    "        self.figures[figureId] = IndexFigure(relPath, fileName, details)\n",
    "        \n",
    "        return self.figures[figureId]\n",
    "\n",
    "\n",
    "    def getHtml(self):\n",
    "        \"\"\"Get the final HTML using the templates\"\"\"\n",
    "\n",
    "        template = os.path.join(projdir, \"docs\", \"template\", \"gallery.template.html\")\n",
    "        with open(template, 'r') as f:\n",
    "            html = f.read()\n",
    "\n",
    "        for detail in self.details:\n",
    "            html = html.replace(\"{\" + f\"{detail}\" + \"}\", self.details[detail])\n",
    "\n",
    "        figuresHtml = \"\"\n",
    "        for figureId in self.figures:\n",
    "            figuresHtml += self.figures[figureId].getHtml() + \"\\n\"\n",
    "\n",
    "        html = html.replace(\"{FIGURE_TEMPLATES}\\n\", figuresHtml)\n",
    "\n",
    "        return html\n",
    "\n",
    "\n",
    "class IndexFigure(Printable):\n",
    "    \"\"\"Simple class to create HTML figure\"\"\"\n",
    "\n",
    "    def __init__(self, relPath, fileName, details):\n",
    "\n",
    "        self.relPath = relPath\n",
    "        self.fileName = fileName\n",
    "        self.details = details\n",
    "\n",
    "        self.details[\"IMAGE_FILENAME\"] = relPath + \"/\" + os.path.basename(fileName)\n",
    "\n",
    "\n",
    "    def createThumb(self, suffix=\"-thumb\"):\n",
    "        \"\"\"Create thumbnail for the figure\"\"\"\n",
    "\n",
    "        root, ext = os.path.splitext(os.path.split(self.fileName)[1])\n",
    "        thumbName = root + suffix + ext\n",
    "        \n",
    "        image = Image.open(self.fileName)\n",
    "        width, height = image.size\n",
    "\n",
    "        self.details[\"IMAGE_WIDTH\"] = str(width)\n",
    "        self.details[\"IMAGE_HEIGHT\"] = str(height)\n",
    "\n",
    "        thumb = image.resize((width // 4, height // 4), Image.ANTIALIAS)\n",
    "        thumb.save(os.path.join(os.path.dirname(self.fileName), thumbName))\n",
    "        \n",
    "        self.details[\"THUMB_FILENAME\"] = os.path.join(self.relPath, thumbName)\n",
    "\n",
    "\n",
    "    def getHtml(self):\n",
    "        \"\"\"Get the final HTML using the templates\"\"\"\n",
    "\n",
    "        template = os.path.join(projdir, \"docs\", \"template\", \"figure.template.html\")\n",
    "        with open(template, 'r') as f:\n",
    "            html = f.read()\n",
    "\n",
    "        for detail in self.details:\n",
    "            html = html.replace(\"{\" + f\"{detail}\" + \"}\", self.details[detail])\n",
    "\n",
    "        return html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Unit Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "............\n",
      "----------------------------------------------------------------------\n",
      "Ran 12 tests in 0.027s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    unittest.main(argv=['first-arg-is-ignored'], exit=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
