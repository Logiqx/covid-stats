{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONS Core\n",
    "\n",
    "Created by Michael George (AKA Logiqx)\n",
    "\n",
    "Website: https://logiqx.github.io/covid-stats/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "Standard python libraries plus determination of projdir, basic printable class, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from datetime import date, datetime, timedelta\n",
    "\n",
    "import csv\n",
    "from xlrd import open_workbook\n",
    "\n",
    "import numpy as np\n",
    "from scipy.interpolate import CubicSpline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import common_core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Data to download from the NHS statistical work area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The 4 nations in the UK\n",
    "nationNames = [\"England\", \"Scotland\", \"Wales\", \"Northern Ireland\"]\n",
    "\n",
    "# The 9 regions in England\n",
    "regionNames = common_core.regionNames\n",
    "\n",
    "# The aliases for regions in England\n",
    "regionAliases = {\"East of England\": [\"East\"]}\n",
    "\n",
    "# Combine all of these area types into a single list\n",
    "areas = [(\"nation\", nationNames), (\"region\", regionNames)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The latest ONS age bands\n",
    "ageDemographics = [\n",
    "    '<1', '1-4', '5-9', '10-14', '15-19', '20-24', '25-29',\n",
    "    '30-34', '35-39', '40-44', '45-49', '50-54', '55-59',\n",
    "    '60-64', '65-69', '70-74', '75-79', '80-84', '85-89', '90+'\n",
    "]\n",
    "\n",
    "# The legacy ONS age bands\n",
    "legacyAgeDemographics = [\n",
    "    '01-14', '15-44', '45-64', '65-74', '75-84', '85+'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "deathsUrl = \"https://www.ons.gov.uk/peoplepopulationandcommunity/birthsdeathsandmarriages/deaths/datasets/weeklyprovisionalfiguresondeathsregisteredinenglandandwales\"\n",
    "deathsPath = os.path.join(common_core.projdir, \"data\", \"ons-deaths\", \"raw\")\n",
    "\n",
    "deathsFiles = [\n",
    "    (\"weekly\", \".*\\.xlsx?$\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants\n",
    "\n",
    "Text strings to avoid hard-coded values throughout the code; avoids clutter and silent errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The epoch for dates in Excel\n",
    "epoch = datetime(1900, 1, 1)\n",
    "\n",
    "# Index from Fri 2 Jan 1970\n",
    "minWeek = date(1970, 1, 2)\n",
    "maxWeek = date(datetime.now().year, 12, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nation names\n",
    "ENGLAND = \"England\"\n",
    "WALES = \"Wales\"\n",
    "ENGLAND_WALES = \"England + Wales\"\n",
    "\n",
    "# England + Wales (historical occurrences)\n",
    "ENGLAND_WALES_OCC = \"England + Wales Occ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worksheet names (lower case)\n",
    "WEEKLY_FIGURES_LOWER = \"weekly figures 20\"\n",
    "ESTIMATED_TOTAL_DEATHS_LOWER = \"estimated total deaths\"\n",
    "COVID_WEEKLY_REGISTRATIONS_LOWER = \"covid-19 - weekly registrations\"\n",
    "COVID_WEEKLY_OCCURRENCES_LOWER = \"covid-19 - weekly occurrences\"\n",
    "\n",
    "# Text used to find specific lines\n",
    "WEEK_NUMBER_TEXT = \"Week number\"\n",
    "WEEK_ENDED_TEXT = \"Week ended\"\n",
    "\n",
    "# Regular expressions used to find specific lines\n",
    "TOTAL_DEATHS_REGEX = \"^Total deaths, all ages\"\n",
    "TOTAL_OCCURRENCES_REGEX = \"^Estimated total death occurrences$\"\n",
    "COVID_DEATHS_REGEX = \"^Deaths involving COVID-19, all ages\"\n",
    "RESPIRATORY_REGEX = \".*ICD-10 J00-J99.*\"\n",
    "\n",
    "# Maximum number of columns to search for text / regex\n",
    "MAX_COLS_WITH_HEADERS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weeks have an end date and a number, always ending on Fridays\n",
    "WEEK_ENDED = \"week_ended\"\n",
    "WEEK_NUMBER = \"week_number\"\n",
    "\n",
    "# Internal names used by the cache\n",
    "WEEK_COL_NOS = \"week_col_nos\"\n",
    "WEEK_NUMBERS = \"week_numbers\"\n",
    "WEEK_ENDINGS = \"week_endings\"\n",
    "WEEK_OFFSETS = \"week_offsets\"\n",
    "\n",
    "# Deaths are reported by registration date and occurrence date\n",
    "TOTAL_REGISTRATIONS = \"total_registrations\"\n",
    "TOTAL_OCCURRENCES = \"total_occurrences\"\n",
    "COVID_REGISTRATIONS = \"covid_registrations\"\n",
    "COVID_OCCURRENCES = \"covid_occurrences\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Spreadsheets\n",
    "\n",
    "Download spreadsheets by parsing the HTML for suitable links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadDeaths(skipExisting=common_core.skipExisting, verbose=common_core.verbose):\n",
    "    \"\"\"Download spreadsheets from ONS website\"\"\"\n",
    "\n",
    "    webDownload = common_core.WebDownload(skipExisting=skipExisting, verbose=verbose)\n",
    "    partNames = webDownload.downloadFiles(deathsPath, deathsUrl, deathsFiles)\n",
    "\n",
    "    # Page did not have a 2021 section and replaced 2020\n",
    "    if \"weekly/publishedweek532020.xlsx\" not in partNames:\n",
    "        partNames += [\"weekly/publishedweek532020.xlsx\"]\n",
    "\n",
    "    return partNames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facilitate Parsing\n",
    "\n",
    "Find specific lines in the spreadsheet, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findRowNo(sheet, heading, aliases = {}):\n",
    "    '''Find rows with the specified headings. Also check for possible aliases.'''\n",
    "\n",
    "    matches = []\n",
    "\n",
    "    # Search for row headings with precise wording\n",
    "    headingLower = heading.lower()\n",
    "\n",
    "    # Aliases are still regarded as precise wording\n",
    "    if heading in aliases:\n",
    "        aliasesLower = [alias.lower() for alias in aliases[heading]]\n",
    "    else:\n",
    "        aliasesLower = []\n",
    "\n",
    "    for rowNo in range(sheet.nrows):\n",
    "        for colNo in range(MAX_COLS_WITH_HEADERS):\n",
    "            cellValue = sheet.cell(rowNo, colNo).value\n",
    "\n",
    "            if isinstance(cellValue, str):\n",
    "                cellValueLower = cellValue.lower()\n",
    "                if cellValueLower == headingLower or cellValueLower in aliasesLower:\n",
    "                    matches.append(rowNo)\n",
    "\n",
    "    if len(matches) == 0:\n",
    "        rowNo = -1\n",
    "    elif len(matches) > 1:\n",
    "        raise RuntimeError(f\"'{heading}' found in '{sheet.name} multiple times - rows {[match + 1 for match in matches]}\")\n",
    "    else:\n",
    "        rowNo = matches[0]\n",
    "\n",
    "    return rowNo\n",
    "\n",
    "\n",
    "def regexFindRowNos(sheet, pattern, verbose = common_core.verbose):\n",
    "    '''Find rows with the specified headings. Also check for possible aliases.'''\n",
    "\n",
    "    matches = []\n",
    "\n",
    "    # Pre-compile regex for minor speedup\n",
    "    regex = re.compile(pattern)\n",
    "\n",
    "    for rowNo in range(sheet.nrows):\n",
    "        for colNo in range(MAX_COLS_WITH_HEADERS):\n",
    "            cellValue = sheet.cell(rowNo, colNo).value\n",
    "\n",
    "            if isinstance(cellValue, str):\n",
    "                if regex.match(cellValue):\n",
    "                    matches.append(rowNo)\n",
    "\n",
    "    if len(matches) > 1 and verbose:\n",
    "        print(f\"WARNING: '{pattern}' found in '{sheet.name}' multiple times - rows {[match + 1 for match in matches]}\")\n",
    "\n",
    "    if len(matches) == 0:\n",
    "        rowNo = -1\n",
    "    else:\n",
    "        rowNo = matches[0]\n",
    "\n",
    "    return rowNo\n",
    "\n",
    "\n",
    "def getWeekColNos(sheet):\n",
    "    '''Determine the columns of week numbers from the cells in the specified row.'''\n",
    "\n",
    "    rowNo = findRowNo(sheet, WEEK_NUMBER_TEXT)\n",
    "    colNos = []\n",
    "\n",
    "    for colNo in range(sheet.ncols):\n",
    "        cellValue = sheet.cell(rowNo, colNo).value\n",
    "\n",
    "        # If the cell contains a value that can be converted to an integer then treat it as a week number\n",
    "        try:\n",
    "            intValue = int(cellValue)\n",
    "            colNos.append(colNo)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return colNos\n",
    "\n",
    "\n",
    "def getWeekNumbers(sheet, colNos):\n",
    "    '''Determine the week numbers from the cells in the specified row.'''\n",
    "\n",
    "    rowNo = findRowNo(sheet, WEEK_NUMBER_TEXT)\n",
    "    weekNumbers = []\n",
    "\n",
    "    for colNo in colNos:\n",
    "        cellValue = sheet.cell(rowNo, colNo).value\n",
    "\n",
    "        weekNumbers.append(int(cellValue))\n",
    "\n",
    "    return weekNumbers\n",
    "\n",
    "\n",
    "def getWeekEndings(sheet, colNos):\n",
    "    '''Determine the week endings from the cells in the specified row.'''\n",
    "\n",
    "    rowNo = findRowNo(sheet, WEEK_ENDED_TEXT)\n",
    "    weekEndings = []\n",
    "\n",
    "    for colNo in colNos:\n",
    "        cellValue = sheet.cell(rowNo, colNo).value\n",
    "\n",
    "        if isinstance(cellValue, str):\n",
    "            weekEnding = datetime.strptime(cellValue, '%d-%b-%y')\n",
    "        else:\n",
    "            weekEnding = epoch + timedelta(days=cellValue - 2)\n",
    "\n",
    "        weekEndings.append(weekEnding.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "    return weekEndings\n",
    "\n",
    "\n",
    "def getWeekOffsets(weekEndings):\n",
    "    '''Determine the week endings from the cells in the specified row.'''\n",
    "\n",
    "    weekOffsets = []\n",
    "\n",
    "    for weekEnding in weekEndings:\n",
    "        weekEnding = datetime.strptime(weekEnding, \"%Y-%m-%d\")\n",
    "            \n",
    "        delta = weekEnding.date() - minWeek\n",
    "        weekOffset = delta.days // 7\n",
    "\n",
    "        weekOffsets.append(weekOffset)\n",
    "\n",
    "    return weekOffsets\n",
    "\n",
    "\n",
    "def getCellValue(sheet, rowNo, colNo):\n",
    "    '''Determine the weekly deaths from the cells in the specified row.'''\n",
    "    \n",
    "    cellValue = sheet.cell(rowNo, colNo).value\n",
    "\n",
    "    # 2011 switched from ICD-10 v 2001 to ICD-10 v 2010 (NCHS)\n",
    "    # 2014 switched from ICD-10 v 2010 (NCHS) to ICD-10 v 2013 (IRIS)\n",
    "    if cellValue == \":\":\n",
    "        cellValue = 0\n",
    "\n",
    "    else:\n",
    "        # Allow non-integers to be treated as zero but show a warning\n",
    "        try:\n",
    "            if cellValue != \"\":\n",
    "                cellValue = int(cellValue)\n",
    "            else:\n",
    "                cellValue = 0\n",
    "        except:\n",
    "            print(f\"Warning: Failed to convert '{cellValue}' to integer in '{sheet.name}' (row {rowNo + 1} col {colNo + 1})\")\n",
    "            cellValue = 0\n",
    "\n",
    "    return cellValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Spreadsheet\n",
    "\n",
    "Stuff more specific to the ONS spreadsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initCache(cache, regionNames):\n",
    "    '''Initialise cache for an individual region'''\n",
    "    \n",
    "    dtype = {'names':[WEEK_ENDED, WEEK_NUMBER, TOTAL_REGISTRATIONS, TOTAL_OCCURRENCES, COVID_REGISTRATIONS, COVID_OCCURRENCES],\n",
    "             'formats':['U10', 'B', 'I', 'I', 'I', 'I']}\n",
    "\n",
    "    # Calculate the maximum array length\n",
    "    delta = maxWeek - minWeek\n",
    "    maxWeeks = delta.days // 7 + 1\n",
    "\n",
    "    # Allocate cache for the region\n",
    "    for regionName in regionNames:\n",
    "        if regionName not in cache:\n",
    "            cache[regionName] = np.zeros(maxWeeks, dtype=dtype)\n",
    "\n",
    "            # Pre-populate week_ended\n",
    "            for weeksDelta in range(maxWeeks):\n",
    "                weekEnding = minWeek + timedelta(weeks=weeksDelta)\n",
    "                cache[regionName][WEEK_ENDED][weeksDelta] = weekEnding.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "def processAreas(cache, sheetsInfo, regionNames):\n",
    "    '''Parse the specified worksheet for weekly deaths in a specific region.'''\n",
    "    \n",
    "    initCache(cache, regionNames)\n",
    "\n",
    "    for sheetInfoKey in sheetsInfo:\n",
    "        sheetInfo = sheetsInfo[sheetInfoKey]\n",
    "\n",
    "        sheet = sheetInfo[\"sheet\"]\n",
    "        weekColNos = sheetInfo[WEEK_COL_NOS]\n",
    "        weekNumbers = sheetInfo[WEEK_NUMBERS]\n",
    "        weekEndings = sheetInfo[WEEK_ENDINGS]\n",
    "        weekOffsets = sheetInfo[WEEK_OFFSETS]\n",
    "\n",
    "        for regionName in regionNames:\n",
    "            if regionName in sheetInfo[\"regions\"]:\n",
    "                rowNo = sheetInfo[\"regions\"][regionName]\n",
    "\n",
    "                for i in range(len(weekColNos)):\n",
    "                    cellValue = getCellValue(sheet, rowNo, weekColNos[i])\n",
    "\n",
    "                    weekNumber = weekNumbers[i]\n",
    "                    weekEnding = weekEndings[i]\n",
    "                    weekOffset = weekOffsets[i]\n",
    "\n",
    "                    assert cache[regionName][WEEK_ENDED][weekOffset] == weekEnding, \"Bug in week offset calculations!\"\n",
    "\n",
    "                    cache[regionName][WEEK_NUMBER][weekOffset] = weekNumber\n",
    "                    cache[regionName][sheetInfoKey][weekOffset] = cellValue\n",
    "\n",
    "\n",
    "def processRegions(cache, sheetsInfo):\n",
    "    '''Parse the specified worksheet for weekly deaths in a specific region.'''\n",
    "\n",
    "    for regionName in common_core.regionNames:\n",
    "        for sheetInfoKey in sheetsInfo:\n",
    "            sheetInfo = sheetsInfo[sheetInfoKey]\n",
    "            sheet = sheetInfo[\"sheet\"]\n",
    "\n",
    "            rowNo = findRowNo(sheet, regionName, regionAliases)\n",
    "\n",
    "            if rowNo >= 0:\n",
    "                sheetInfo[\"regions\"][regionName] = rowNo\n",
    "\n",
    "    processAreas(cache, sheetsInfo, common_core.regionNames)\n",
    "\n",
    "\n",
    "def processNations(cache, sheetsInfo):\n",
    "    '''Parse the specified worksheet for weekly deaths in a specific country.'''\n",
    "\n",
    "    regionNames = [ENGLAND_WALES, WALES]\n",
    "    \n",
    "    for regionName in regionNames:\n",
    "        for sheetInfoKey in sheetsInfo:\n",
    "            sheetInfo = sheetsInfo[sheetInfoKey]\n",
    "            sheet = sheetInfo[\"sheet\"]\n",
    "\n",
    "            if regionName == ENGLAND_WALES:\n",
    "                if sheet.name.lower().startswith(WEEKLY_FIGURES_LOWER):\n",
    "                    rowNo = regexFindRowNos(sheet, TOTAL_DEATHS_REGEX)\n",
    "                elif sheet.name.lower().startswith(ESTIMATED_TOTAL_DEATHS_LOWER):\n",
    "                    rowNo = regexFindRowNos(sheet, TOTAL_OCCURRENCES_REGEX)\n",
    "                else:\n",
    "                    rowNo = regexFindRowNos(sheet, COVID_DEATHS_REGEX)\n",
    "            else:\n",
    "                rowNo = findRowNo(sheet, regionName)\n",
    "\n",
    "            if rowNo >= 0:\n",
    "                sheetInfo[\"regions\"][regionName] = rowNo\n",
    "                \n",
    "    processAreas(cache, sheetsInfo, regionNames)\n",
    "\n",
    "\n",
    "def processSheets(cache, sheetsInfo):\n",
    "    '''Parse the specified worksheets for weekly deaths.'''\n",
    "\n",
    "    for sheetInfoKey in sheetsInfo:\n",
    "        sheetInfo = sheetsInfo[sheetInfoKey]\n",
    "        sheet = sheetInfo[\"sheet\"]\n",
    "\n",
    "        weekColNos = getWeekColNos(sheet)\n",
    "        sheetInfo[WEEK_COL_NOS] = weekColNos\n",
    "\n",
    "        weekNos = getWeekNumbers(sheet, weekColNos)\n",
    "        assert len(weekNos) == len(weekColNos), f\"Number of week numbers did not match number of weeks in '{sheet.name}'\"\n",
    "        sheetInfo[WEEK_NUMBERS] = weekNos\n",
    "        \n",
    "        weekEndings = getWeekEndings(sheet, weekColNos)\n",
    "        assert len(weekEndings) == len(weekColNos), f\"Number of week endings did not match number of weeks in '{sheet.name}'\"\n",
    "        sheetInfo[WEEK_ENDINGS] = weekEndings\n",
    "\n",
    "        weekOffsets = getWeekOffsets(weekEndings)\n",
    "        assert len(weekOffsets) == len(weekEndings), f\"Number of week offsets did not match number of weeks in '{sheet.name}'\"\n",
    "        sheetInfo[WEEK_OFFSETS] = weekOffsets\n",
    "\n",
    "        sheetInfo[\"regions\"] = {}\n",
    "\n",
    "    processRegions(cache, sheetsInfo)\n",
    "    processNations(cache, sheetsInfo)\n",
    "\n",
    "\n",
    "def processWorkbook(cache, workbook):\n",
    "    '''Parse the specified workbook for weekly deaths.'''\n",
    "\n",
    "    sheetsInfo = {}\n",
    "\n",
    "    for sheet in workbook.sheets():           \n",
    "        if sheet.name.lower().startswith(WEEKLY_FIGURES_LOWER):\n",
    "            sheetsInfo[TOTAL_REGISTRATIONS] = {\"sheet\": sheet}\n",
    "        elif sheet.name.lower().startswith(ESTIMATED_TOTAL_DEATHS_LOWER):\n",
    "            sheetsInfo[TOTAL_OCCURRENCES] = {\"sheet\": sheet}\n",
    "        elif sheet.name.lower() == COVID_WEEKLY_REGISTRATIONS_LOWER:\n",
    "            sheetsInfo[COVID_REGISTRATIONS] = {\"sheet\": sheet}\n",
    "        elif sheet.name.lower() == COVID_WEEKLY_OCCURRENCES_LOWER:\n",
    "            sheetsInfo[COVID_OCCURRENCES] = {\"sheet\": sheet}\n",
    "            \n",
    "    processSheets(cache, sheetsInfo)\n",
    "\n",
    "\n",
    "def getWorkbookYear(workbook):\n",
    "    '''Scan the specified workbook to determine the year.'''\n",
    "\n",
    "    year = None\n",
    "\n",
    "    for sheet in workbook.sheets():           \n",
    "        if sheet.name.lower().startswith(WEEKLY_FIGURES_LOWER):\n",
    "            year = int(sheet.name[-4:])\n",
    "\n",
    "    if year == None:\n",
    "        raise RuntimeError(f\"Year could not be determined for workbook\")\n",
    "\n",
    "    return year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data\n",
    "\n",
    "Turn data from lists into CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveArea(cache, areaType, areaName):\n",
    "    '''Save data in cache to CSV'''\n",
    "\n",
    "    header = ','.join(cache[areaName].dtype.names)\n",
    "    \n",
    "    # Ensure CSV path exists\n",
    "    csvPath = os.path.join(common_core.projdir, \"data\", \"ons-deaths\", \"csv\", \"weekly\", \"deaths\", areaType)\n",
    "    if not os.path.exists(csvPath):\n",
    "        os.makedirs(csvPath)\n",
    "\n",
    "    # Determine safe filename\n",
    "    csvFn = os.path.join(csvPath, common_core.getSafeName(areaName) + \".csv\")\n",
    "\n",
    "    # Save data to CSV\n",
    "    np.savetxt(csvFn, cache[areaName], fmt='%s', delimiter=',', header=header, comments='')\n",
    "\n",
    "\n",
    "def saveRegions(cache):\n",
    "    '''Save extracted data for all regions'''\n",
    "\n",
    "    for regionName in common_core.regionNames:\n",
    "        saveArea(cache, \"region\", regionName)\n",
    "    \n",
    "    \n",
    "def saveNations(cache):\n",
    "    '''Save extracted data for supported nations'''\n",
    "\n",
    "    for nationName in [ENGLAND_WALES, WALES]:\n",
    "        saveArea(cache, \"nation\", nationName)\n",
    "    \n",
    "    \n",
    "def saveCache(cache):\n",
    "    '''Save all extracted data to CSV'''\n",
    "\n",
    "    saveRegions(cache)\n",
    "    saveNations(cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spreadsheet Interface\n",
    "\n",
    "Main interface for converting from XLSX files to CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadExcelFiles(partNames):\n",
    "    '''Load the specified spreadsheets into cache.'''\n",
    "\n",
    "    # Iterate through all workbooks to determine the years\n",
    "    years = {}\n",
    "    for partName in partNames:\n",
    "        fileName = os.path.join(common_core.projdir, \"data\", \"ons-deaths\", \"raw\", partName)\n",
    "        workbook = open_workbook(fileName)\n",
    "\n",
    "        year = getWorkbookYear(workbook)\n",
    "        years[year] = workbook\n",
    "\n",
    "    # Iterate throught the years in chronological order - required to handle the 2021 hybrid!\n",
    "    cache = {}\n",
    "    for year in sorted(years):\n",
    "        try:\n",
    "            processWorkbook(cache, years[year])\n",
    "        except:\n",
    "            print(f\"ERROR: Exception raise whilst processing workbook for {year}\")\n",
    "            raise\n",
    "\n",
    "    return(cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Regional Occurrences\n",
    "\n",
    "Use the ONS modelled occurrences to calculate regional occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadCsvFile(areaType, areaName):\n",
    "    '''Load CSV file into numpy array'''\n",
    "    csvPath = os.path.join(common_core.projdir, \"data\", \"ons-deaths\", \"csv\", \"weekly\", \"deaths\", areaType)\n",
    "    csvFn = os.path.join(csvPath, common_core.getSafeName(areaName) + \".csv\")\n",
    "\n",
    "    try:\n",
    "        with open(csvFn, 'r') as f:\n",
    "            reader = csv.reader(f, delimiter = ',')\n",
    "\n",
    "            dtype = []\n",
    "            converters = {}\n",
    "            colNames = next(reader)\n",
    "\n",
    "            for i in range(len(colNames)):\n",
    "                colName = colNames[i]\n",
    "                if colName == WEEK_ENDED:\n",
    "                    dtype.append((colName, \"U10\"))\n",
    "                else:\n",
    "                    dtype.append((colName, \"u4\"))\n",
    "                    converters[i] = lambda s: int(s or 0)\n",
    "\n",
    "            data = np.genfromtxt(f, dtype=dtype, converters=converters, delimiter=\",\")\n",
    "\n",
    "    except:\n",
    "        print(f\"Failed to load CSV data for {areaName}\")\n",
    "        raise\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "def loadCsvFiles():\n",
    "    '''Convert weekly registrations into weekly occurrences'''\n",
    "    \n",
    "    cache = {}\n",
    "    \n",
    "    for nationName in [ENGLAND_WALES, WALES]:\n",
    "        cache[nationName] = loadCsvFile(\"nation\", nationName)\n",
    "\n",
    "    for regionName in common_core.regionNames:\n",
    "        cache[regionName] = loadCsvFile(\"region\", regionName)\n",
    "\n",
    "    return cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotData(cache, areaNames, maxWeeks = 52):\n",
    "    '''Plot data for visual inspection'''\n",
    "    \n",
    "    # week_ended, week_number, total_registrations, covid_registrations, covid_occurrences\n",
    "    # week_ended, week_number, total_deaths\n",
    "    \n",
    "    ewData = cache[ENGLAND_WALES]\n",
    "\n",
    "    for areaName in areaNames:\n",
    "        areaData = cache[areaName]\n",
    "\n",
    "        figure = plt.figure(clear=True, figsize=(16, 6))  \n",
    "        plt.title(areaName)\n",
    "        plt.ylabel('Number of deaths')\n",
    "\n",
    "        try:\n",
    "            y_points = areaData[TOTAL_OCCURRENCES][-maxWeeks:]\n",
    "            x_points = np.arange(len(y_points))       \n",
    "            plt.plot(x_points, y_points, label = \"Total Occurrences\", color='green')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            y_points = areaData[TOTAL_REGISTRATIONS][-maxWeeks:]\n",
    "            x_points = np.arange(len(y_points))       \n",
    "            plt.plot(x_points, y_points, label = \"Total Registrations\", color='lightsteelblue')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            #y_points = ewData[TOTAL_OCCURRENCES] * areaData[TOTAL_REGISTRATIONS] / ewData[TOTAL_REGISTRATIONS]\n",
    "            x_points = np.arange(len(y_points))\n",
    "            #plt.plot(x_points, y_points, label = \"Estimated Occurrences\", color='navy')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            y_points = areaData[COVID_OCCURRENCES][-maxWeeks:]\n",
    "            x_points = np.arange(len(y_points))       \n",
    "            plt.plot(x_points, y_points, label = \"COVID Occurrences\", color='red')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        x_ticks = np.array(areaData[WEEK_ENDED])[-maxWeeks:]\n",
    "        plt.xticks(np.arange(0, len(x_ticks), step=1), x_ticks[::1], rotation=90)\n",
    "\n",
    "        plt.yticks(np.arange(0, 24000, 1000))\n",
    "        #figure.get_yaxis().set_major_formatter(mpl.ticker.StrMethodFormatter('{x:,.0f}'))\n",
    "        #plt.get_yaxis().set_major_formatter(matplotlib.ticker.FuncFormatter(lambda x, p: format(int(x), ',')))\n",
    "        #plt.rc('ytick', labelsize=500) \n",
    "        \n",
    "        plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateOccurrencesW53(cache):\n",
    "    '''Calculate the estimated number of occurrences for week 53 of 2020'''\n",
    "\n",
    "    indexW53 = np.where(cache[ENGLAND_WALES][WEEK_ENDED] == '2021-01-01')[0][0]\n",
    "    \n",
    "    # Take minimum of 4 weeks before and 4 weeks afterwards\n",
    "    yBefore = cache[ENGLAND_WALES][TOTAL_OCCURRENCES][indexW53 - 4:indexW53]\n",
    "    yAfter = cache[ENGLAND_WALES][TOTAL_OCCURRENCES][indexW53 + 1:indexW53 + 5]\n",
    "    y = np.hstack((yBefore, yAfter))\n",
    "    \n",
    "    # y values need to correspond to the x values\n",
    "    xBefore = np.arange(len(yBefore))\n",
    "    xAfter = np.arange(len(yAfter)) + 5\n",
    "    x = np.hstack((xBefore, xAfter))\n",
    "    \n",
    "    # Calculate the missing point using Cubic Spline\n",
    "    cs = CubicSpline(x, y)\n",
    "\n",
    "    cache[ENGLAND_WALES][TOTAL_OCCURRENCES][indexW53] = cs(4)\n",
    "    \n",
    "\n",
    "def polyfillCache(cache):\n",
    "    '''Calculate missing values using whatever method is appropriate'''\n",
    "\n",
    "    calculateOccurrencesW53(cache)\n",
    "\n",
    "    \n",
    "def trimCache(cache):\n",
    "    '''Remove rows from cache which don't contain any useful data'''\n",
    "    \n",
    "    for areaName in cache:\n",
    "        populated = np.where(cache[areaName][TOTAL_REGISTRATIONS] > 0)[0]\n",
    "        cache[areaName] = cache[areaName][populated[0]:populated[-1] + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Check / download latest spreadsheets\n",
    "    #partNames = downloadDeaths()\n",
    "    #cache = loadExcelFiles(partNames)\n",
    "    \n",
    "    # Tidy up the data, prior to saving in CSV format\n",
    "    #trimCache(cache)\n",
    "    #polyfillCache(cache)\n",
    "    #saveCache(cache)\n",
    "    \n",
    "    # Cache can either be re-used or loaded from CSV files\n",
    "    cache = loadCsvFiles()\n",
    "\n",
    "    # Simple charts for review\n",
    "    #areaNames = [ENGLAND_WALES, WALES] + common_core.regionNames\n",
    "    areaNames = [ENGLAND_WALES]\n",
    "    #plotData(cache, areaNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
